---
title: "Computational Musicology"
author: "Dewi Timman"
date: "`r format(Sys.Date(), '%e %B %Y')`"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(spotifyr)
library(plotly)
library(compmus)
library(fontawesome)
```

# `r fa("house-chimney")`  Introduction {.storyboard}

### Introduction

```{r corpus setup, include=FALSE}
corpus <- get_playlist_audio_features("", "3jblLN3iqoULSfQGHAFYVe")
```

My corpus is a playlist with `r nrow(corpus)` songs.
What do all the songs have in common?
They are all songs I like.
It is a very diverse list with songs ranging from film music to _Shawn Mendes_ to _The Sidh_ to _Maria Mena_.
But there is one specific artist I listen to significantly more than any other artist: _Sleeping At Last_.
_Sleeping At Last_ is an artist that has all kinds of projects for himself.
For example, he makes songs about upcoming astronomical events (_Astronomy_ series), or about involuntary human development (_Atlas II_ series).
He also has a podcast on Spotify about how he makes his songs.
_Sleeping At Last_ has a thin line with film music.
His music can be heard often in films and series.
But his music also comes in contact with more popular artists: he has made some covers.
Because of these things, he is easy to compare to other songs in the playlist.
However, I am not interested in how _Sleeping At Last_ compares to the other artists, but I am interested in how he differs from the other songs in the playlist.
What makes _Sleeping At Last_ _Sleeping At Last_?
Why is this the artist I listen to most often?
Are there other artists with the same characteristics?

I think that to get an even deeper understanding of the style of _Sleeping At Last_, there are a few songs that are most interesting to look at.
First, one or more _astronomy_ songs from _Sleeping At Last_.
These are the songs that are very typical for _Sleeping At Last_.
Both in the sense of the subject and the kind of music and instruments.
Moreover, it would be nice to look at one or more of the songs that are included in a film or TV series and compare it to another song in that film or TV series to see what is so special about this song being there.
Furthermore, one or more of his covers can be compared to the original to see how the styles differ and get to know more about this specific style of _Sleeping At Last_.

```{r corpus setup sleeping at last, include=FALSE}
sleeping_at_last_tracks <- get_artist_audio_features("sleeping at last")
corpus$sleeping <- ifelse(corpus$track.id %in% sleeping_at_last_tracks$track_id, 1, 0)
```

***

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/3jblLN3iqoULSfQGHAFYVe?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

<!-- To do lijstje: -->
<!-- * word cloud met titels -->
<!-- * volgorde grafiekjes omdraaien: eerst sleeping at last, dan overig -->
<!-- * andere afstandsmetingen gebruiken in chroma plotje -->
<!-- * chromatogram -->
<!-- * flexdash thema -->
<!-- * titels en assen van plotjes nog een keer checken -->
<!-- * in-text linkjes naar alle liedjes -->
<!-- * {data-commentary-width=400} -->

<!-- Feedback om te verwerken: -->
<!-- *  Meer verwachtingen in de introductie -->
<!-- *  The only downside I can think of is that you have so many songs that the size of the danceability gets lost a bit. But I really like the darker clusters in the graph. Think about what they mean and explain them. -->
<!-- * One plot that might also help, especially with the amount of "Other songs" would be a barplot with the x axis being one of the features and the y axis being the song count or proportions, giving you more insights on the ratios instead of concrete numbers. -->

# What characteristics do _Sleeping At Last_ songs have? {.storyboard data-icon="fa-music"}

### Keygram of _June 24, 2022: Parade of Planets_ [tonal analysis]

```{r keygram setup, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```

```{r keychram corpus setup, echo=FALSE}
astronomy_key <- get_track_audio_features("4kZhLfs3nsJu8JBqEXdxNW")$key

astronomy <-
  get_tidy_audio_analysis("4kZhLfs3nsJu8JBqEXdxNW") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r keygram, echo=FALSE}
astronomy |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if desired
    method = "cosine",  # Try different distance metrics
    norm = "chebyshev"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

***

This is a keygram from one of _Sleeping At Lasts_ astronomy songs: [_June 24, 2022: Parade of Planets_](https://open.spotify.com/track/4kZhLfs3nsJu8JBqEXdxNW?si=f5fa16753a9a4176). According to Spotify, the key in general is B. It is a song about the planetary alignment that could be observed on June 24, 2022. Seven of the planets could be seen aligned in the sky around that time. There also is a [podcast episode about this song](https://open.spotify.com/episode/2FVj0AD4PNPHee0cHS6MDr?si=f8badc32e4bb4e81) in which the artist tells that every planet has its own melody and they come together in this song. The piano, violin and cello are heard throughout the song and connect everything. 

When we take a closer look at the song, it can be seen that the song starts in B major. Then, around 1:40 it is unclear what the key of that section is. Maybe the variety of instruments (piano, cello and violin) and melodies makes Spotify wondering what the key is. A bit after two minutes there is a change in key: the song changes to C# minor. This change can also be heard in the song: first a violin and a piano are playing and then the song changes to cello, piano and singing. Especially the singing makes the song sound different. Then, approximately 30 seconds later, it becomes unclear again what the keys of the sections are. We can hear the same instruments and melody as the last time this happened. This also finalizes the song.

### Histogram of keys [track-level features]

```{r histogram keys, echo=FALSE}
colors <- RColorBrewer::brewer.pal(7, "PuOr")
labels <- c('C','C#/Db','D','D#/Eb','E','F','F#/Gb','G','G#/Ab','A','A#/Bb','B')

duration <- ggplot(corpus) + 
  geom_histogram(aes(key, y=..density.., color=as.factor(sleeping), fill=as.factor(sleeping)), position="identity", lwd=0.2, alpha=0.6, binwidth=1) +
  scale_color_manual(values=c(colors[1], colors[7]), labels = c("Other songs", "Sleeping At Last songs")) +
  scale_fill_manual(values=c(colors[2], colors[6]), labels = c("Other songs", "Sleeping At Last songs")) +
  scale_x_continuous(breaks=0:11, labels=labels) +
  labs(color='', fill='', x='Key', y='Relative density')

theme <- theme_minimal() +
  theme(panel.grid.minor=element_blank(),
        axis.line=element_line(), 
        plot.title = element_text(hjust = 0.5))

duration + theme + theme(panel.grid = element_blank(), legend.position=c(0.8,0.8))
```

***

In this histogram it can be seen that _Sleeping At Last_ has more songs in the C and D#/Eb keys and less songs in the C#/Db, D, E, and A keys in general. 

### Valence, acousticness, danceability and instrumentalness [track-level features]

```{r track-level features plot, echo=FALSE}
plot <- ggplot(corpus) +
  geom_point(aes(x=valence, y=acousticness, size=danceability, color=instrumentalness, text=track.name), alpha=0.4, shape=21) +
  geom_rug(aes(x=valence, y=acousticness, color=instrumentalness)) +
  facet_grid(cols = vars(sleeping), labeller=as_labeller(c(`0`='Other songs', `1`='Sleeping At Last songs'))) +
  labs(title='Different track-level features of Sleeping At Last songs\ncompared to other songs in the chosen playlist') +
  scale_color_distiller(palette='PuOr') + 
  scale_x_continuous(breaks=c(0,0.5,1),limits=c(0,1)) +
  scale_y_continuous(breaks=c(0,0.5,1), limits=c(0,1))

theme <- theme_minimal() +
  theme(panel.grid.minor=element_blank(),
        axis.line=element_line(), 
        plot.title = element_text(hjust = 0.5))

ggplotly(plot + theme)
```

***

In this graphic, the track-level features valence, acousticness, instrumentalness and danceability are shown for the _Sleeping At Last_ songs in the playlist compared to the other songs in the playlist.
The graphic shows that _Sleeping At Last songs_ have a higer acousticness than the other songs in general, whereas the valence and danceability tend to be lower.
In addition, the proportion of instrumental songs seems to be bigger in the _Sleeping At Last_ songs than in the other songs.

### Duration [track-level features]

```{r duration setup, include=FALSE}
corpus <- corpus %>%
  mutate(track.duration_min = track.duration_ms / (1000 * 60))

duration_mean_sleeping <- corpus %>%
  filter(sleeping == 1) %>%
  summarize(mean = mean(track.duration_min))

duration_mean_other <- corpus %>%
  filter(sleeping == 0) %>%
  summarize(mean = mean(track.duration_min))
```

```{r duration plot, echo=FALSE}
colors <- RColorBrewer::brewer.pal(7, "PuOr")

duration <- ggplot(corpus) + 
  geom_histogram(aes(track.duration_min, y=..density.., color=as.factor(sleeping), fill=as.factor(sleeping)), position="identity", lwd=0.2, alpha=0.6, binwidth=0.25) +
  geom_vline(xintercept=duration_mean_sleeping$mean, color=colors[7], linetype='dotdash') +
  geom_vline(xintercept=duration_mean_other$mean, color=colors[1], linetype='dotdash') +
  scale_color_manual(values=c(colors[1], colors[7]), labels = c("Other songs", "Sleeping At Last songs")) +
  scale_fill_manual(values=c(colors[2], colors[6]), labels = c("Other songs", "Sleeping At Last songs")) +
  labs(color='', fill='', x='Duration (min)', y='Relative density')

duration + theme + theme(panel.grid = element_blank(), legend.position=c(0.8,0.8))
```

***

In this plot it can be seen that the songs from _Sleeping At Last_ are shorter in general in comparison to the other songs in the playlist. He does not have any outliers to the right and has more shorter songs. 

### Chromagram of the song _Dark Horse_ by _Sleeping At Last_ [chroma features]

```{r chroma sleeping setup, echo=FALSE}
dark_horse_sleeping <- get_tidy_audio_analysis("1i5PW20LSYwCQMjVQgSXVM") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

norms_chroma <- list("euclidean", "manhattan", "chebyshev")
dists_chroma <- list("manhattan", "aitchison", "cosine", "angular")
summary_chroma <- list("mean", "aitchison_centre", "root_mean_square", "max")
```

```{r chroma sleeeping, echo=FALSE}
dark_horse_sleeping |>
  mutate(pitches = map(pitches, compmus_normalise, norms_chroma[3])) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

***

In this chromagram the song _Dark Horse_ by _Sleeping At Last_ is shown using the Chebyshev normalization metric. It can be seen that the notes B, A, F# and C# are played most often. This is not surprising, since the key of the song is in F#. 

### Differences in tempo of the song _Dark Horse_ by _Katy Perry_ and _Sleeping At Last_ [chroma features]

```{r dtw setup, echo=FALSE}
dark_horse_katy <- get_tidy_audio_analysis("4jbmgIyjGoXjY01XxatOx6") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
```

```{r dynamic time warping plot, echo=FALSE}
dark_horse_dist <- compmus_long_distance(
  dark_horse_katy %>% mutate(pitches = map(pitches, compmus_normalise, norms_chroma[3])),
  dark_horse_sleeping %>% mutate(pitches = map(pitches, compmus_normalise, norms_chroma[3])),
  feature = pitches,
  method = dists_chroma[2]
)

dark_horse <- dark_horse_dist %>%
  mutate(dark_horse_sleeping = xstart + xduration / 2,
         dark_horse_katy = ystart + yduration / 2) %>%
  ggplot(aes(x=dark_horse_sleeping, y=dark_horse_katy, fill=d)) +
    geom_tile(aes(width=xduration, height=yduration)) +
    coord_fixed() + 
    scale_x_continuous(breaks=c(16,51,89,123,163,192,209,221), labels=c("I knew you were", "So you wanna play with magic?", "Mark my words", "So you wanna play with magic?", "So you wanna play with magic?", "There's no going back (first time)", "There's no going back (last time)", "")) + 
    scale_y_continuous(breaks = c(15, 45, 80, 110, 139, 183, 210, 216), labels=c("I knew you were", "So you wanna play with magic?", "Mark my words", "So you wanna play with magic?", "Uh, she's a beast", "So you wanna play with magic?", "There's no going back", "")) + 
    scale_fill_viridis_c(option = "E", guide = "none") +
    theme_classic() +
    theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
    labs(x = "Sleeping At Last", y = "Katy Perry")

dark_horse
```

***

In this plot the tempo differences between _Katy Perry_ and _Sleeping At Last_ are shown for the song _Dark Horse_. The more yellow we see, the more different the tempo in the two songs is. 
It can be seen that, although there are some points in the song where both artists have the same tempo, _Katy Perry's_ tempo is a bit faster in general.
At the end of the song, _Sleeping At Last_ deviates from the original song by skipping over the bridge (starting with "Uh, she's a beast") and repeating 'There's no going back' multiple times.

### Chromagram of the song _Taste_ from _Sleeping At Last_ [chroma features]

```{r chroma taste, echo=FALSE}
taste <- get_tidy_audio_analysis("6usFrqlplLLU9OUDq936iE") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

taste_chrom <- taste |>
  mutate(pitches = map(pitches, compmus_normalise, norms_chroma[3])) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

ggplotly(taste_chrom)
```

***

What can. we see here?

### Structure of the song _Taste_ from _Sleeping At Last_ [chroma and timbre features] {data-commentary-width=450}

```{r self sim, echo=FALSE}
norms_timbre <- list("euclidean", "manhattan", "chebyshev")
dists_timbre <- list("euclidean", "cosine", "angular")
summary_timbre <- list("mean", "root_mean_square")

taste2 <-
  get_tidy_audio_analysis("6usFrqlplLLU9OUDq936iE") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = summary_chroma[4], norm = norms_chroma[3]
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = summary_timbre[1]
      )
  )
```

```{r self sim matrices, echo=FALSE}
self_sim <- bind_rows(
  taste2 |> 
    compmus_self_similarity(pitches, dists_chroma[1]) |> 
    mutate(d = d / max(d), type = "Chroma"),
  taste2 |> 
    compmus_self_similarity(timbre, dists_timbre[2]) |> 
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "")

self_sim_ggplotly <- ggplotly(self_sim, domain = list(x=c(0,1), y=c(0.6,1)))

parts <- data.frame(
  Chroma = c("0:00 - 0:23", "0:23 - 0:49", "0:49 - 1:12", "1:12 - 1:20", "1:20 - 2:28", ""), 
  Timbre = c("0:00 - 0:23", "0:23 - 1:12", "", "1:12 - 1:20", "1:20 - 1:24", "1:24 - 1:28"),
  Chroma2 = c("", "2:28 - 3:08", "3:08 - 4:11", "", "4:11 - 4:19", ""), 
  Timbre2 = c("1:28 - 2:28", "2:28 - 3:08", "3:08 - 3:35", "3:35 - 4:11", "4:11 - 4:19", ""))
```

```{r subplot, echo=FALSE}
parts_table <- plot_ly(
    type = 'table',
    domain = list(x=c(0,1), y=c(0,0.4)),
    header = list(values = c("Chroma", "Timbre", "Chroma", "Timbre")),
    cells = list(values = rbind(parts$Chroma, parts$Timbre, parts$Chroma2, parts$Timbre2), height=25)
  )

subplot(self_sim_ggplotly, parts_table, nrows=2)
```

***

The two self-similarity matrices illustrate pitch- (chroma) and timbre-based self-similarity within the song _Taste_ from _Sleeping At Last_. The song is instrumental so no clear parallel diagonal lines are seen in both graphs. However, a clear structure can be seen. The different parts from both graphs can be seen in the table below.

At the start of the song, a little melody can be heard which continues throughout the whole song. Multiple instruments join this melody. Around 0:23 the piano comes in and the music starts to be louder. This can be seen in both chroma and timbre graphs. Then, around 0:45, some background singing can be heard which leads to a kind of 'explosion' which happens around 0:49. This can be seen in the chroma graph. Around 1:12 the music settles down again which can be seen in both graphs. Around 1:20 drums are introduced which can be seen in the chroma graph. At 1:24 a flute is heard which becomes increasingly louder until the rhythm of the music increases around 1:28 and guitars can be heard clearly (seen in the timbre graph). Until 2:28 some previous parts repeat itself, but no clear difference can be seen. However, at 2:28 the music settles down again and continues slowly (seen in both graphs). Some background singing starts and at the start of the third minute some tension builds up until around 3:08, where a new rhythm starts with different instruments (seen in both graphs). At 3:35 the music continues with some background singing and some flute whistling (seen in the timbre graph) until it reaches 4:11. At this point, the music settles down until it fades away at 4:19 (seen in both graphs).

When the music instruments change, it can be seen that the timbre graph changes. We can see some instrument groups reappearing throughout the music. This can also be heard. You hear a flute and some background music coming and going throughout the song. But also the starting instruments are coming back in the song. However, if there is only a change in melody and not in instruments, we can see the chroma graph changing. This is the case, for example, after one of the 'explosions' you can hear in the song. If the melody as well as the music instruments change, this is shown in both graphs.

# `r fa("magnifying-glass")`  Results
